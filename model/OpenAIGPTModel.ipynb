{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYAElqaFVMDS",
        "outputId": "0f2cab4c-38c3-4889-ac2e-2bc02fe432b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.26.4.tar.gz (55 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m55.6/55.6 KB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from openai) (3.8.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai) (4.64.1)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.8/dist-packages (from openai) (2.25.1)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (2.1.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.8.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (22.2.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Building wheels for collected packages: openai\n",
            "  Building wheel for openai (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.26.4-py3-none-any.whl size=67744 sha256=71154dbe8ce9e745b0b09f25d75445bf2e9497df802ef9d1d0616830cecf824d\n",
            "  Stored in directory: /root/.cache/pip/wheels/2b/d8/4e/268f029bd3277c1dd9e8781a0e0296e0a63822665bfa2429fc\n",
            "Successfully built openai\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.26.4\n"
          ]
        }
      ],
      "source": [
        "#openai library installation \n",
        "\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zTy-85s3VEwJ"
      },
      "outputs": [],
      "source": [
        "#installing necessary libraries\n",
        "\n",
        "import os\n",
        "import openai\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vAAEHNtlVmYC"
      },
      "outputs": [],
      "source": [
        "#openai API key\n",
        "\n",
        "openai.api_key = \"OPENAI_API_KEY\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZb1eZ9aVvkI",
        "outputId": "14490841-a73c-4d31-930c-d9f6dea0de0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Analyzing...\n",
            "\n",
            "- Based on your file extension, your file is formatted as a CSV file\n",
            "- Your file contains 31 prompt-completion pairs. In general, we recommend having at least a few hundred examples. We've found that performance tends to linearly increase for every doubling of the number of examples\n",
            "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://beta.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
            "- Your data does not contain a common ending at the end of your completions. Having a common ending string appended to the end of the completion makes it clearer to the fine-tuned model where the completion should end. See https://beta.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples.\n",
            "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://beta.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
            "\n",
            "Based on the analysis we will perform the following actions:\n",
            "- [Necessary] Your format `CSV` will be converted to `JSONL`\n",
            "- [Recommended] Add a suffix separator ` ->` to all prompts [Y/n]: Y\n",
            "- [Recommended] Add a suffix ending ` END` to all completions [Y/n]: Y\n",
            "- [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: Y\n",
            "\n",
            "\n",
            "Your data will be written to a new JSONL file. Proceed [Y/n]: Y\n",
            "\n",
            "Wrote modified file to `train_dataset_prepared.jsonl`\n",
            "Feel free to take a look!\n",
            "\n",
            "Now use that file when fine-tuning:\n",
            "> openai api fine_tunes.create -t \"train_dataset_prepared.jsonl\"\n",
            "\n",
            "After youâ€™ve fine-tuned a model, remember that your prompt has to end with the indicator string ` ->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\" END\"]` so that the generated texts ends at the expected place.\n",
            "Once your model starts training, it'll approximately take 2.87 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
          ]
        }
      ],
      "source": [
        "#initiating batch command to convert data from csv into jsonl format\n",
        "\n",
        "!openai tools fine_tunes.prepare_data -f \"train_dataset.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uf6sJp7HZZyG",
        "outputId": "2b7722a3-893e-425b-f9bc-43bc3dd68529"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"bytes\": 3453,\n",
            "  \"created_at\": 1675194928,\n",
            "  \"filename\": \"file\",\n",
            "  \"id\": \"file-eawTfL69aryl8zbKVdN7c790\",\n",
            "  \"object\": \"file\",\n",
            "  \"purpose\": \"fine-tune\",\n",
            "  \"status\": \"uploaded\",\n",
            "  \"status_details\": null\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "#creating file id of the jsonl document\n",
        "\n",
        "with open(\"train_dataset_prepared.jsonl\") as f:\n",
        "  response = openai.File.create(file=f, purpose='fine-tune')\n",
        "  print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Xh5gtuz4ZA_w"
      },
      "outputs": [],
      "source": [
        "#setting the api key as environment variable\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = \"OPENAI_API_KEY\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Fi1-w3yWDzQ",
        "outputId": "dac0289d-9ce6-4c1c-fbc8-8552bffb3949"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\rUpload progress:   0% 0.00/3.45k [00:00<?, ?it/s]\rUpload progress: 100% 3.45k/3.45k [00:00<00:00, 3.10Mit/s]\n",
            "Uploaded file from train_dataset_prepared.jsonl: file-hUurZZRNruiyPAjJgiueEj1a\n",
            "Created fine-tune: ft-fuwGsx42zLQbsSw9x2U7qSY1\n",
            "Streaming events until fine-tuning is complete...\n",
            "\n",
            "(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n",
            "[2023-01-31 19:55:50] Created fine-tune: ft-fuwGsx42zLQbsSw9x2U7qSY1\n",
            "[2023-01-31 19:57:41] Fine-tune costs $0.07\n",
            "[2023-01-31 19:57:42] Fine-tune enqueued. Queue number: 26\n",
            "[2023-01-31 19:59:58] Fine-tune is in the queue. Queue number: 25\n",
            "\n",
            "Stream interrupted (client disconnected).\n",
            "To resume the stream, run:\n",
            "\n",
            "  openai api fine_tunes.follow -i ft-fuwGsx42zLQbsSw9x2U7qSY1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!openai api fine_tunes.create -t \"train_dataset_prepared.jsonl\" -m davinci"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkOTu8rVc7n3",
        "outputId": "7606bf5f-8591-4c1a-8dbc-871437461f49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-01-31 19:55:50] Created fine-tune: ft-fuwGsx42zLQbsSw9x2U7qSY1\n",
            "[2023-01-31 19:57:41] Fine-tune costs $0.07\n",
            "[2023-01-31 19:57:42] Fine-tune enqueued. Queue number: 26\n",
            "[2023-01-31 19:59:58] Fine-tune is in the queue. Queue number: 25\n",
            "[2023-01-31 20:04:08] Fine-tune is in the queue. Queue number: 24\n",
            "[2023-01-31 20:04:49] Fine-tune is in the queue. Queue number: 23\n",
            "[2023-01-31 20:08:36] Fine-tune is in the queue. Queue number: 22\n",
            "[2023-01-31 20:10:30] Fine-tune is in the queue. Queue number: 21\n",
            "[2023-01-31 20:13:37] Fine-tune is in the queue. Queue number: 20\n",
            "[2023-01-31 20:17:01] Fine-tune is in the queue. Queue number: 19\n",
            "[2023-01-31 20:17:02] Fine-tune is in the queue. Queue number: 18\n",
            "[2023-01-31 20:17:36] Fine-tune is in the queue. Queue number: 17\n",
            "[2023-01-31 20:20:19] Fine-tune is in the queue. Queue number: 16\n",
            "[2023-01-31 20:20:36] Fine-tune is in the queue. Queue number: 15\n",
            "[2023-01-31 20:21:12] Fine-tune is in the queue. Queue number: 14\n",
            "[2023-01-31 20:23:35] Fine-tune is in the queue. Queue number: 13\n",
            "[2023-01-31 20:24:45] Fine-tune is in the queue. Queue number: 12\n",
            "[2023-01-31 20:26:53] Fine-tune is in the queue. Queue number: 11\n",
            "[2023-01-31 20:27:33] Fine-tune is in the queue. Queue number: 10\n",
            "[2023-01-31 20:28:25] Fine-tune is in the queue. Queue number: 9\n",
            "[2023-01-31 20:31:04] Fine-tune is in the queue. Queue number: 8\n",
            "[2023-01-31 20:31:45] Fine-tune is in the queue. Queue number: 7\n",
            "[2023-01-31 20:32:03] Fine-tune is in the queue. Queue number: 6\n",
            "[2023-01-31 20:33:42] Fine-tune is in the queue. Queue number: 5\n",
            "[2023-01-31 20:34:51] Fine-tune is in the queue. Queue number: 4\n",
            "[2023-01-31 20:34:52] Fine-tune is in the queue. Queue number: 3\n",
            "[2023-01-31 20:35:36] Fine-tune is in the queue. Queue number: 2\n",
            "[2023-01-31 20:35:48] Fine-tune is in the queue. Queue number: 1\n",
            "[2023-01-31 20:38:27] Fine-tune is in the queue. Queue number: 0\n",
            "[2023-01-31 20:38:46] Fine-tune started\n",
            "[2023-01-31 20:40:33] Completed epoch 1/4\n",
            "[2023-01-31 20:40:42] Completed epoch 2/4\n",
            "[2023-01-31 20:40:51] Completed epoch 3/4\n",
            "[2023-01-31 20:41:00] Completed epoch 4/4\n",
            "[2023-01-31 20:41:50] Uploaded model: davinci:ft-xpertvr-georgian-team-2023-01-31-20-41-50\n",
            "[2023-01-31 20:41:51] Uploaded result file: file-yaOKakSQaxr1KfmlGn5YqyPo\n",
            "[2023-01-31 20:41:51] Fine-tune succeeded\n",
            "\n",
            "Job complete! Status: succeeded ðŸŽ‰\n",
            "Try out your fine-tuned model:\n",
            "\n",
            "openai api completions.create -m davinci:ft-xpertvr-georgian-team-2023-01-31-20-41-50 -p <YOUR_PROMPT>\n"
          ]
        }
      ],
      "source": [
        "!openai api fine_tunes.follow -i ft-fuwGsx42zLQbsSw9x2U7qSY1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training of second Dataset"
      ],
      "metadata": {
        "id": "23xc8VrHZr_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#initiating batch command to convert data from csv into jsonl format\n",
        "\n",
        "!openai tools fine_tunes.prepare_data -f \"train_2.csv\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrVsoe2VZqtp",
        "outputId": "22b02995-8cc4-47ca-c30f-1ad49b72179b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzing...\n",
            "\n",
            "- Based on your file extension, your file is formatted as a CSV file\n",
            "- Your file contains 71 prompt-completion pairs. In general, we recommend having at least a few hundred examples. We've found that performance tends to linearly increase for every doubling of the number of examples\n",
            "- `completion` column/key should not contain empty strings. These are rows: [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70]\n",
            "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://beta.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
            "- Your data does not contain a common ending at the end of your completions. Having a common ending string appended to the end of the completion makes it clearer to the fine-tuned model where the completion should end. See https://beta.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples.\n",
            "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://beta.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
            "\n",
            "Based on the analysis we will perform the following actions:\n",
            "- [Necessary] Your format `CSV` will be converted to `JSONL`\n",
            "- [Necessary] Remove 39 rows with empty completions\n",
            "- [Recommended] Add a suffix separator ` ->` to all prompts [Y/n]: Y\n",
            "- [Recommended] Add a suffix ending `\\n` to all completions [Y/n]: Y\n",
            "- [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: Y\n",
            "\n",
            "\n",
            "Your data will be written to a new JSONL file. Proceed [Y/n]: Y\n",
            "\n",
            "Wrote modified file to `train_2_prepared.jsonl`\n",
            "Feel free to take a look!\n",
            "\n",
            "Now use that file when fine-tuning:\n",
            "> openai api fine_tunes.create -t \"train_2_prepared.jsonl\"\n",
            "\n",
            "After youâ€™ve fine-tuned a model, remember that your prompt has to end with the indicator string ` ->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\"\\n\"]` so that the generated texts ends at the expected place.\n",
            "Once your model starts training, it'll approximately take 3.91 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creating file id of the jsonl document\n",
        "\n",
        "with open(\"train_2_prepared.jsonl\") as f:\n",
        "  response = openai.File.create(file=f, purpose='fine-tune')\n",
        "  print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLeBHR5caY0_",
        "outputId": "61928371-29a4-438d-823e-2ad45994d31c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"bytes\": 3558,\n",
            "  \"created_at\": 1675279071,\n",
            "  \"filename\": \"file\",\n",
            "  \"id\": \"file-1t91UlGhTvkh5UBNwOO3IGBv\",\n",
            "  \"object\": \"file\",\n",
            "  \"purpose\": \"fine-tune\",\n",
            "  \"status\": \"uploaded\",\n",
            "  \"status_details\": null\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!openai api fine_tunes.create -t \"train_2_prepared.jsonl\" -m davinci"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_4hxSu5af6k",
        "outputId": "2e534798-5d8e-4e3c-9bae-f34f6840e443"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rUpload progress:   0% 0.00/3.56k [00:00<?, ?it/s]\rUpload progress: 100% 3.56k/3.56k [00:00<00:00, 4.68Mit/s]\n",
            "Uploaded file from train_2_prepared.jsonl: file-As2Xjkf3I78M5SXv6cfQFmpT\n",
            "Created fine-tune: ft-60qBFOrZOA0ShAQM1b8btNYa\n",
            "Streaming events until fine-tuning is complete...\n",
            "\n",
            "(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n",
            "[2023-02-01 19:18:08] Created fine-tune: ft-60qBFOrZOA0ShAQM1b8btNYa\n",
            "[2023-02-01 19:19:32] Fine-tune costs $0.07\n",
            "[2023-02-01 19:19:33] Fine-tune enqueued. Queue number: 3\n",
            "[2023-02-01 19:19:45] Fine-tune is in the queue. Queue number: 2\n",
            "[2023-02-01 19:20:41] Fine-tune is in the queue. Queue number: 1\n",
            "[2023-02-01 19:22:13] Fine-tune is in the queue. Queue number: 0\n",
            "[2023-02-01 19:22:17] Fine-tune started\n",
            "[2023-02-01 19:25:10] Completed epoch 1/4\n",
            "[2023-02-01 19:25:19] Completed epoch 2/4\n",
            "[2023-02-01 19:25:32] Completed epoch 3/4\n",
            "[2023-02-01 19:25:41] Completed epoch 4/4\n",
            "[2023-02-01 19:26:22] Uploaded model: davinci:ft-xpertvr-georgian-team-2023-02-01-19-26-22\n",
            "[2023-02-01 19:26:23] Uploaded result file: file-aAh5DUp5PvNpfFKlRuR4Wsc6\n",
            "[2023-02-01 19:26:23] Fine-tune succeeded\n",
            "\n",
            "Job complete! Status: succeeded ðŸŽ‰\n",
            "Try out your fine-tuned model:\n",
            "\n",
            "openai api completions.create -m davinci:ft-xpertvr-georgian-team-2023-02-01-19-26-22 -p <YOUR_PROMPT>\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}